{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGNATEコンペ 特有のコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout,Input,Flatten,Activation\n",
    "from keras.layers import Conv1D,Conv2D,MaxPooling1D,BatchNormalization,Reshape\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "## 音声解析用\n",
    "import scipy.signal as ss\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from Util import NormalizeHorizontalDirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声データのData Augmentation\n",
    "def change_speed_and_pitch(x,sr):\n",
    "    y_pitch_speed = x.copy()\n",
    "    # you can change low and high here\n",
    "    length_change = np.random.uniform(low=0.5,high=1.5)\n",
    "    speed_fac = 1.0  / length_change\n",
    "    print(\"resample length_change = \",length_change)\n",
    "    tmp = np.interp(np.arange(0,len(y_pitch_speed),speed_fac),np.arange(0,len(y_pitch_speed)),y_pitch_speed)\n",
    "    minlen = min(y_pitch_speed.shape[0], tmp.shape[0])\n",
    "    y_pitch_speed *= 0\n",
    "    y_pitch_speed[0:minlen] = tmp[0:minlen]\n",
    "#    ipd.Audio(y_pitch_speed, rate=sr)\n",
    "    return y_pitch_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_pitch(x,sr):\n",
    "    y_pitch = x.copy()\n",
    "    bins_per_octave = 24\n",
    "    pitch_pm = 4\n",
    "    pitch_change =  pitch_pm * 2*(np.random.uniform()-0.5)   \n",
    "    print(\"pitch_change = \",pitch_change)\n",
    "    y_pitch = librosa.effects.pitch_shift(y_pitch.astype('float64'), \n",
    "                                          sr, n_steps=pitch_change, \n",
    "                                          bins_per_octave=bins_per_octave)\n",
    "    return (y_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_speed(x,sr):\n",
    "    y_speed = x.copy()\n",
    "    speed_change = np.random.uniform(low=0.7,high=1.3)\n",
    "    print(\"speed_change = \",speed_change)\n",
    "    tmp = librosa.effects.time_stretch(y_speed.astype('float64'), speed_change)\n",
    "    minlen = min(y_speed.shape[0], tmp.shape[0])\n",
    "    y_speed *= 0 \n",
    "    y_speed[0:minlen] = tmp[0:minlen]    \n",
    "    return y_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x,sr):\n",
    "    y_noise = x.copy()\n",
    "    # you can take any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n",
    "    noise = 0.005\n",
    "    noise_amp = noise*np.random.uniform()*np.amax(y_noise)\n",
    "    y_noise = y_noise.astype('float64') + noise_amp * np.random.normal(size=y_noise.shape[0])\n",
    "#    ipd.Audio(y_noise, rate=sr)\n",
    "    return y_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slightly_timeshift(x,sr):\n",
    "    y_shift = x.copy()\n",
    "    change_length_rate = 0.1 # up to 10% of length\n",
    "    timeshift_fac = change_length_rate *2*(np.random.uniform()-0.5)\n",
    "    print(\"timeshift_fac = \",timeshift_fac)\n",
    "    start = int(y_shift.shape[0] * timeshift_fac)\n",
    "    print(start)\n",
    "    if (start > 0):\n",
    "        y_shift = np.pad(y_shift,(start,0),mode='constant')[0:y_shift.shape[0]]\n",
    "    else:\n",
    "        y_shift = np.pad(y_shift,(0,-start),mode='constant')[0:y_shift.shape[0]]\n",
    "    return y_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stfft(extract_x,sr):\n",
    "    frame_bin = int(sr * (10 ** (-3)))\n",
    "    f, t, Zxx = ss.stft(extract_x,fs = sr,\n",
    "                    window = ss.get_window(\"hamming\",frame_bin * 25),# 25ms\n",
    "                    nperseg = frame_bin * 25, \n",
    "                    noverlap = frame_bin * 15,# 15msずつoverlapしていることになる    \n",
    "                    nfft = 1023 # ここが1024で動くのがよくわからん。\n",
    "                   )\n",
    "    spectral = np.abs(Zxx)\n",
    "    #周波数方向に正規化\n",
    "    #Zxx_norm = calc_zscore(spectral)\n",
    "    #正規化は秒数で抽出してから。\n",
    "    return((f,t,spectral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(spectrogram,thre=500):\n",
    "    n_col = spectrogram.shape[1]\n",
    "    if n_col >= thre:\n",
    "        # 音声がデフォルトだと500ms以上の場合\n",
    "        # data augmentationでsligntly shftを導入したので、lbのランダム化はやめる\n",
    "#        lb =  np.random.randint(0,thre - n_col + 1)\n",
    "        lb = 0\n",
    "        ub = thre + lb\n",
    "        spectrogram_pad = spectrogram[:,lb:ub]\n",
    "        \n",
    "    else:\n",
    "        # lbをランダムに設定\n",
    "        # lb = np.random.randint(0,thre - n_col + 1)\n",
    "        lb = 0\n",
    "        ub = thre - n_col - lb\n",
    "        spectrogram_pad = np.pad(spectrogram,((0,0),(lb,ub)),\"constant\")\n",
    "\n",
    "    return(spectrogram_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spectrogram(filepath,lb_ms=0,ub_ms=500,speed=False,pitch=False,time_shift=False,noise=False):\n",
    "    # データの読み込み\n",
    "    x,sr = librosa.load(filepath)\n",
    "    \n",
    "    if(speed and pitch):\n",
    "        # 音声のスピードとピッチを変化\n",
    "        print(\"change speed and pitch\")\n",
    "        x = change_speed_and_pitch(x,sr)\n",
    "\n",
    "    elif(speed):\n",
    "        # 音声のスピードを変化\n",
    "        print(\"change speed\")\n",
    "        x = change_speed(x,sr)\n",
    "        \n",
    "    elif(pitch):\n",
    "        # 音声のピッチを変化\n",
    "        print(\"change pitch\")\n",
    "        x = change_pitch(x,sr)\n",
    "    \n",
    "    if(time_shift):\n",
    "        # 時間方向に音声を少しずらす\n",
    "        print(\"time_shift\")\n",
    "        x = slightly_timeshift(x,sr)\n",
    "    \n",
    "    if(noise):\n",
    "        # 音声にノイズを添加する\n",
    "        print(\"add noise\")\n",
    "        x = add_noise(x,sr)\n",
    "                        \n",
    "    ft,t,spectrogram = stfft(x,sr)\n",
    "    # TODO : 周波数方向のnormalizationを追加\n",
    "    spectrogram_norm = NormalizeHorizontalDirection(spectrogram[:,lb_ms:ub_ms])\n",
    "    \n",
    "    spectrogram_norm_pad = zero_padding(spectrogram_norm,thre=500)\n",
    "    \n",
    "    # TODO : zero padding\n",
    "    return(spectrogram_norm_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramGenerator(keras.callbacks.Callback):\n",
    "    def __init__(self,lb,ub,train_info,speaker_dict,batch_size,time_len,test_info,milestones):\n",
    "#        self.reset()        \n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        #self.train_info = train_info\n",
    "        # 学習する際は__init__の時点でcalc_spectrogram_funcを設定する必要はない。\n",
    "        self.calc_spectrogram_func = lambda filepath: calc_spectrogram(filepath,\n",
    "                                                               lb_ms=lb,ub_ms=ub,\n",
    "                                                               speed=False,pitch=False,\n",
    "                                                               time_shift=False,noise=False)\n",
    "        \n",
    "        X_train,X_val,y_train,y_val = train_test_split(np.array(train_info[\"filepath\"]),\n",
    "                                                 np.array(train_info[\"label\"]),\n",
    "                                                            test_size=0.1,\n",
    "                                                random_state = 1234)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.speaker_dict = speaker_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.time_len = time_len\n",
    "        \n",
    "        # step_per_epoch        \n",
    "        self.train_step_per_epoch = int(np.ceil(len(X_train) / batch_size))\n",
    "        self.val_step_per_epoch = int(np.ceil(len(X_val) / batch_size))\n",
    "        \n",
    "        # テストデータ\n",
    "        X_test = np.array(test_info[\"filepath\"])\n",
    "        self.X_test = X_test\n",
    "        # y_testはダミーを加えておく\n",
    "        self.y_test = np.repeat(\"FE_AD\",len(test_info[\"filepath\"]))\n",
    "        self.test_step_per_epoch = int(np.ceil(len(X_test) / batch_size))        \n",
    "        \n",
    "        ## カリキュラム学習\n",
    "        self.milestones = milestones\n",
    "        \n",
    "    def reset(self):\n",
    "        self.spectrograms = []\n",
    "        self.labels = []\n",
    "\n",
    "    def next_train(self):\n",
    "        ## FIXME : lb_msとub_msはmili secondではない。milisecond * 10*-1\n",
    "        self.reset()\n",
    "        num_classes = len(self.speaker_dict)\n",
    "        \n",
    "        while True:\n",
    "            # train_test_splitでshuffleしているが、epoch毎に学習順を変更\n",
    "            indexes = np.random.permutation(len(self.X_train))\n",
    "            X = self.X_train[indexes]\n",
    "            y = self.y_train[indexes]\n",
    "                \n",
    "            for tmp_X,tmp_y in zip(X,y):\n",
    "#                spectrogram = np.zeros([512,500])\n",
    "#                print(tmp_X)\n",
    "                spectrogram = self.calc_spectrogram_func(tmp_X)\n",
    "\n",
    "                \n",
    "                target = to_categorical(self.speaker_dict[tmp_y],num_classes=num_classes)\n",
    "                \n",
    "                self.spectrograms.append(spectrogram)\n",
    "                self.labels.append(target)\n",
    "                \n",
    "                if len(self.labels) == self.batch_size:\n",
    "                    inputs = np.asarray(self.spectrograms, dtype=np.float32).reshape(self.batch_size,\n",
    "                                                                                   spectrogram.shape[0],\n",
    "                                                                                    spectrogram.shape[1],1)\n",
    "                    targets = np.asarray(self.labels, dtype=np.float32)\n",
    "                    \n",
    "                    assert len(targets) == self.batch_size, \"incorect target shape\"\n",
    "                    \n",
    "                    self.reset()\n",
    "                    yield (inputs,targets)\n",
    "                    \n",
    "    def next_val(self):\n",
    "        self.reset()\n",
    "        ## FIXME : lb_msとub_msはmili secondではない。milisecond * 10*-1\n",
    "        num_classes = len(self.speaker_dict)\n",
    "        \n",
    "        while True:\n",
    "#            indexes = np.random.permutation(len(self.X_val))\n",
    "#            X = self.X_train[indexes]\n",
    "#            y = self.y_train[indexes]\n",
    "                \n",
    "            for tmp_X,tmp_y in zip(self.X_val,self.y_val):\n",
    "#                print(tmp_X)\n",
    "                spectrogram = self.calc_spectrogram_func(tmp_X)\n",
    "                \n",
    "                target = to_categorical(self.speaker_dict[tmp_y],num_classes=num_classes)\n",
    "                \n",
    "                self.spectrograms.append(spectrogram)\n",
    "                self.labels.append(target)\n",
    "                \n",
    "                if len(self.labels) == self.batch_size:\n",
    "                    inputs = np.asarray(self.spectrograms, dtype=np.float32).reshape(self.batch_size,\n",
    "                                                                                   spectrogram.shape[0],\n",
    "                                                                                    spectrogram.shape[1],1)\n",
    "                    targets = np.asarray(self.labels, dtype=np.float32)\n",
    "                    self.reset()\n",
    "                    yield (inputs,targets)\n",
    "        \n",
    "    def test(self):\n",
    "        self.reset()\n",
    "        ## FIXME : lb_msとub_msはmili secondではない。milisecond * 10*-1\n",
    "        num_classes = len(self.speaker_dict)\n",
    "        \n",
    "        while True:                \n",
    "            for tmp_X,tmp_y in zip(self.X_test,self.y_test):\n",
    "            # テストデータではdata augmentationはしない\n",
    "#                print(tmp_X)\n",
    "                spectrogram = calc_spectrogram(tmp_X,\n",
    "                                               lb_ms=self.lb,ub_ms=self.ub,\n",
    "                                               speed=False,pitch=False,\n",
    "                                               time_shift=False,noise=False)\n",
    "                \n",
    "                target = to_categorical(self.speaker_dict[tmp_y],num_classes=num_classes)\n",
    "                \n",
    "                self.spectrograms.append(spectrogram)\n",
    "                self.labels.append(target)\n",
    "                \n",
    "                if len(self.labels) == self.batch_size:\n",
    "                    inputs = np.asarray(self.spectrograms, dtype=np.float32).reshape(self.batch_size,\n",
    "                                                                                   spectrogram.shape[0],\n",
    "                                                                                    spectrogram.shape[1],1)\n",
    "                    targets = np.asarray(self.labels, dtype=np.float32)\n",
    "                    self.reset()\n",
    "                    yield (inputs,targets)\n",
    "                \n",
    "    \n",
    "    def on_train_begin(self):\n",
    "        self.reset()\n",
    "        self.calc_spectrogram_func = lambda filepath: calc_spectrogram(filepath,\n",
    "                                                               lb_ms=self.lb,ub_ms=self.ub,\n",
    "                                                               speed=False,pitch=False,\n",
    "                                                               time_shift=False,noise=False)\n",
    "            \n",
    "    def on_epoch_begin(self):\n",
    "        # カリキュラム学習を導入 (学習が進むごとにData Augmentationを導入する)\n",
    "#        milestones = [1,2,3,4,5]\n",
    "        \n",
    "        if epoch <= self.milestones[0]:\n",
    "        # data augmentationなし\n",
    "            self.calc_spectrogram_func = lambda filepath: calc_spectrogram(filepath,\n",
    "                                                                   lb_ms=self.lb,ub_ms=self.ub,\n",
    "                                                                   speed=False,pitch=False,\n",
    "                                                                   time_shift=False,noise=False)\n",
    "        elif epoch <= self.milestones[1]:\n",
    "        # time shift\n",
    "            self.calc_spectrogram_func = lambda filepath: calc_spectrogram(filepath,\n",
    "                                                                   lb_ms=self.lb,ub_ms=self.ub,\n",
    "                                                                   speed=False,pitch=False,\n",
    "                                                                   time_shift=True,noise=False)        \n",
    "        elif epoch <= self.milestones[2]:\n",
    "        # speed 変更\n",
    "            self.calc_spectrogram_func = lambda filepath: calc_spectrogram(filepath,\n",
    "                                                                   lb_ms=self.lb,ub_ms=self.ub,\n",
    "                                                                   speed=True,pitch=False,\n",
    "                                                                   time_shift=True,noise=False)\n",
    "        elif epoch <= self.milestones[3]:\n",
    "        # pitch変更\n",
    "            self.calc_spectrogram_func = lambda filepath: calc_spectrogram(filepath,\n",
    "                                                                   lb_ms=self.lb,ub_ms=self.ub,\n",
    "                                                                   speed=True,pitch=True,\n",
    "                                                                   time_shift=True,noise=False)\n",
    "        elif epoch <= self.milestones[4]:\n",
    "        # noiseを添加\n",
    "            self.calc_spectrogram_func = lambda filepath: calc_spectrogram(filepath,\n",
    "                                                                   lb_ms=self.lb,ub_ms=self.ub,\n",
    "                                                                   speed=True,pitch=True,\n",
    "                                                                   time_shift=True,noise=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43915482/how-do-you-create-a-custom-activation-function-with-keras\n",
    "# 上記参考\n",
    "def log_relu(x):\n",
    "    return(K.log(K.relu(x)+0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モデル、コールバックの定義\n",
    "def build_cldnns(input_shape,num_classes):\n",
    "    \n",
    "    # ラベルの数\n",
    "    output_dim = num_classes\n",
    "\n",
    "    #学習モデルの構築\n",
    "    sr = 22050\n",
    " #   duration_sec = 3\n",
    "\n",
    "    conv_filters = 400\n",
    "    \n",
    "    kernel_size = 3\n",
    "#    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "\n",
    "    window_size_sec = 35 * (10 ** -3)\n",
    "\n",
    "#    input_shape = [duration_sec*sr,1]\n",
    "\n",
    "    # TODO : Conv1Dに変更    \n",
    "\n",
    "    act = 'relu'\n",
    "\n",
    "    input_data = Input(name='the_input', \n",
    "                       shape=input_shape, \n",
    "                       dtype='float32')\n",
    "\n",
    "    inner = Conv1D(filters = conv_filters, \n",
    "                   kernel_size = int(window_size_sec * sr),\n",
    "                   padding='valid',\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   name='conv1')(input_data)\n",
    "\n",
    "    inner = MaxPooling1D(pool_size= input_shape[0] - int(window_size_sec * sr) + 1, name='max1')(inner)\n",
    "\n",
    "    inner = Activation(log_relu,name=\"act1\")(inner)\n",
    "    #inner = Activation(\"relu\",name=\"act1\")(inner)\n",
    "    #inner = Activation(log_relu,name=\"relu\")(inner)\n",
    "\n",
    "    inner = Reshape((conv_filters,1),name=\"reshape1\")(inner)\n",
    "\n",
    "    inner = Conv1D(filters=256,\n",
    "                   kernel_size= 8, padding='valid',\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   activation=\"relu\",#linear\n",
    "                   name='conv2')(inner)\n",
    "\n",
    "    #inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "    # 以下のactivationをするなら、conv2のactをlinearにする\n",
    "    #inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "\n",
    "    inner = MaxPooling1D(pool_size = 3, \n",
    "                         name='max2')(inner)\n",
    "\n",
    "    timesteps = 32\n",
    "    data_dim = 512\n",
    "    rnn_size = 832\n",
    "\n",
    "    inner = LSTM(rnn_size, return_sequences=True,\n",
    "                 input_shape=(timesteps, data_dim),\n",
    "                 name = \"lstm1\")(inner)\n",
    "\n",
    "    inner = LSTM(rnn_size, return_sequences=True,\n",
    "                 input_shape=(timesteps, data_dim),\n",
    "                 name = \"lstm2\")(inner)\n",
    "\n",
    "    inner = LSTM(rnn_size, return_sequences=True,\n",
    "                 input_shape=(timesteps, data_dim),\n",
    "                 name = \"lstm3\")(inner)\n",
    "\n",
    "    inner = Flatten(name = \"flatten\")(inner)\n",
    "\n",
    "    inner = Dense(1024,name = \"dense1\")(inner)\n",
    "\n",
    "    inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "    inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "    out = Dense(output_dim,activation=\"sigmoid\",name = \"dense2\")(inner)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=out)\n",
    "\n",
    "    #lr = 0.001でうまくいかなければ、ADAMにしてもよいかも\n",
    "    # callbacksにf1 scoreを追加したい\n",
    "    # https://qiita.com/koshian2/items/81abfc0a75ea99f726b9\n",
    "    \n",
    "    # Adamのデフォルト学習率に設定\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "    sgd = SGD(lr=LEARNING_RATE,\n",
    "              decay=1e-6, \n",
    "              momentum=0.9,\n",
    "              nesterov=True,\n",
    "              clipnorm=5)\n",
    "\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=sgd,metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawWaveGenerator(keras.callbacks.Callback):\n",
    "    def __init__(self,minibatchsize,duration_sec,data_df,label2int,shuffle = True):\n",
    "        self.duration_sec = duration_sec\n",
    "        self.minibatchsize = minibatchsize \n",
    "        self.cur_index = 0\n",
    "      #  self.wave_length = wave_length\n",
    "#        self.step = step\n",
    "        self.data_df = data_df\n",
    "        self.data_size = data_df.shape[0]\n",
    "        self.iteration = np.floor(self.data_size/minibatchsize)\n",
    "        self.sr = 22050\n",
    "        self.label2int = label2int\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def shuffle_df(self):\n",
    "        # 学習データの学習順序をシャッフル\n",
    "        self.data_df = self.data_df.sample(frac=1).reset_index(drop=True) #.loc[self.cur_index:self.cur_index+self.minibatchsize-1,:]\n",
    "    \n",
    "    def get_batch(self,minibatchsize,duration_sec):\n",
    "        \n",
    "        num_classes = len(self.label2int)\n",
    "        \n",
    "        inputs = np.zeros([minibatchsize,duration_sec*self.sr,1])\n",
    "        outputs = np.zeros([minibatchsize,num_classes])\n",
    "        \n",
    "        train_batch_df = self.data_df.loc[self.cur_index:self.cur_index+self.minibatchsize-1,:]\n",
    "#        print(self.cur_index)\n",
    "#        print(self.cur_index+minibatchsize-1)\n",
    "#       print(train_batch_df)\n",
    "        for i,(index,v) in enumerate(train_batch_df.iterrows()):\n",
    "            #    print(v)\n",
    "           # print(i)\n",
    "            label = v[\"label\"]\n",
    "            wave_path = v[\"raw_wave_path\"]\n",
    "    \n",
    "            with open(wave_path,mode=\"rb\") as f:\n",
    "                tmp = pickle.load(f)\n",
    "                sr = tmp[\"sampling_rate\"]\n",
    "                raw_wave = tmp[\"raw_wave\"]\n",
    "\n",
    "            # 基本的にサンプリングレートは22050のはず\n",
    "            assert sr == 22050\n",
    "\n",
    "            # 変数名aは小さなスコープしかないから許して\n",
    "            a = raw_wave[:duration_sec*sr]\n",
    "            # データがduration秒\n",
    "            a = np.pad(a, [0,duration_sec*sr-len(a)],'constant')\n",
    "            \n",
    "#            print(a.shape)\n",
    "#            print(inputs.shape)\n",
    "#            print(i)\n",
    "\n",
    "            inputs[i,:,0] = a\n",
    "            outputs[i,:] = to_categorical(self.label2int[label],num_classes=num_classes)\n",
    "            \n",
    "        self.cur_index = self.cur_index + minibatchsize\n",
    "        \n",
    "        return (inputs,outputs)\n",
    "                \n",
    "    def next_train(self):\n",
    "        self.cur_index = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.shuffle_df()\n",
    "        \n",
    "        while True:    \n",
    "            if self.cur_index / self.minibatchsize > self.iteration:\n",
    "                self.cur_index = 0\n",
    "            yield self.get_batch(minibatchsize = self.minibatchsize,\n",
    "                                 duration_sec = self.duration_sec)\n",
    "\n",
    "#    def next_val(self):\n",
    "#        while True:           \n",
    "#            yield self.get_batch(minibatchsize = self.minibatchsize,\n",
    "#                                 duration_sec = self.duration_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1loss, macro_f1 metricsを定義\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    \n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sr = 22050\n",
    "    duration_sec = 3\n",
    "    input_shape = [sr*duration_sec,1]\n",
    "    num_classes = 6\n",
    "    #models = build_cldnns(input_shape,num_classes)\n",
    "    \n",
    "    ## TODO : 上記、クラス、関数のテストコードを以下に記載\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # SpectrogramGeneratorのテスト\n",
    "    # 学習データの読み込み\n",
    "    # ワーキングディレクトリの設定\n",
    "    \n",
    "    ## 学習データ\n",
    "    work_dir = \"/home/taichi/DataAnalysis/05_NTT_corevo/\"\n",
    "    \n",
    "    train_info = pd.read_csv(work_dir + \"01_input/ntt_corevo/class_train.tsv\",\n",
    "                        delimiter = \"\\t\",\n",
    "                        names = [\"filename\",\"label\"])\n",
    "\n",
    "    train_info[\"filepath\"] = work_dir + \"01_input/ntt_corevo/train/\" + train_info[\"filename\"] + \".wav\"\n",
    "    \n",
    "    ## テストデータ\n",
    "    test_info = pd.read_csv(work_dir + \"03_work/test_time_distribution.csv\")\n",
    "    \n",
    "    test_info[\"filepath\"] = work_dir + \"01_input/ntt_corevo/\" + test_info[\"filename\"] + \".wav\"\n",
    "        \n",
    "    ## Generatorのパラメタを定義\n",
    "    with open(work_dir + \"03_work/label2int.pickle\",mode = \"rb\") as f:\n",
    "        label2int = pickle.load(f)\n",
    "        \n",
    "    lb=0\n",
    "    ub=500\n",
    "    speaker_dict=label2int\n",
    "    BATCH_SIZE=7\n",
    "    time_len = 500\n",
    "    \n",
    "    milestones = [-1,-1,-1,-1,100]\n",
    "    datagen = SpectrogramGenerator(lb,ub,train_info,#.head(n),\n",
    "                                     speaker_dict,BATCH_SIZE,time_len,test_info,\n",
    "                                   milestones)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
