{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display # 波形のプロットに必要\n",
    "import IPython.display as ipd #jupyter-notebook上で音声再生\n",
    "import glob\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.signal as ss\n",
    "import os\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# モデル可視化用\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーティリティ関数の読み込み\n",
    "from Util import NormalizeHorizontalDirection\n",
    "from Util import DefineModel\n",
    "#from Util import SpectrogramDataGenerator\n",
    "\n",
    "from project_utility import f1,f1_loss\n",
    "\n",
    "# resnet構築に必要な関数、クラスを読み込み\n",
    "# resnetの構築に必要なライブラリを読み込み\n",
    "from resnet import compose,ResNetConv2D,ResnetBuilder,shortcut,basic_block,residual_blocks,bottleneck\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100%!important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# jupyter-notebookのcellの幅を広げる\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container{width:100%!important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作業ディレクトリの設定\n",
    "os.chdir(\"/home/taichi/DataAnalysis/05_NTT_corevo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv(\"01_input/ntt_corevo/class_train.tsv\",\n",
    "                        delimiter = \"\\t\",\n",
    "                        names = [\"filename\",\"label\"])\n",
    "\n",
    "train_info[\"filepath\"] = \"03_work/spectrogram/\" + train_info[\"filename\"] + \".pickle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/spectrogram/0002f1cd968ca78ada9e1c7037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/spectrogram/0003747ec9268461d4cbb9e1b8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/spectrogram/0003b32f378b001f0f73bf0981...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/spectrogram/0004ab975bf8b59e1b19f2b7b6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/spectrogram/0005678b57ca265a65f8ef0cc7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                            filepath  \n",
       "0  03_work/spectrogram/0002f1cd968ca78ada9e1c7037...  \n",
       "1  03_work/spectrogram/0003747ec9268461d4cbb9e1b8...  \n",
       "2  03_work/spectrogram/0003b32f378b001f0f73bf0981...  \n",
       "3  03_work/spectrogram/0004ab975bf8b59e1b19f2b7b6...  \n",
       "4  03_work/spectrogram/0005678b57ca265a65f8ef0cc7...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルをintegerに変換するdict\n",
    "label2int = {}\n",
    "for i,v in enumerate(np.unique(train_info[\"label\"])):\n",
    "    label2int[v] = i\n",
    "\n",
    "# クラスラベルのサイズ\n",
    "num_classes = len(np.unique(train_info[\"label\"]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの分割\n",
    "# データを学習データと評価用データに分割\n",
    "X_train,X_val,y_train,y_val = train_test_split(np.array(train_info[\"filepath\"]),\n",
    "                                                 np.array(train_info[\"label\"]),\n",
    "                                                            test_size=0.1,\n",
    "                                                random_state = 1234)\n",
    "\n",
    "# 学習データ内に複数の同一話者が存在するせいかlocal CVがうまく計算できないのでやめる。\n",
    "# 学習データセットを分割し、モデル選択用のデータセットを作成\n",
    "#X_train,X_val,y_train,y_val = train_test_split(X_train,\n",
    "#                                               y_train,\n",
    "#                                               test_size = 0.1,\n",
    "#                                              random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スペクトログラム(入力データ)のサイズ\n",
    "input_shape = (512,300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを定義\n",
    "###model = DefineModel(input_shape,num_classes)\n",
    "model = ResnetBuilder.build_resnet_50(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(model,show_shapes=True).create(prog=\"dot\",format=\"svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEARNING_RATE = 0.000002\n",
    "#model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "#                      optimizer=SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
    "#                      metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss = f1_loss,\n",
    "                      optimizer=SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
    "                      metrics=[f1,'accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのジェネレータを定義\n",
    "class SpectrogramDataGenerator(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "#        self.num_classes = num_classes\n",
    "\n",
    "    def reset(self):\n",
    "        self.spectrograms = []\n",
    "        self.labels = []\n",
    "        \n",
    "    def zero_padding(self,spectral,thre):\n",
    "        n_col = spectral.shape[1]\n",
    "        if n_col >= thre :\n",
    "            spectral_pad = spectral[:,0:thre]\n",
    "        else:\n",
    "            # lbをランダムに設定\n",
    "           # lb = np.random.randint(0,thre - n_col + 1)\n",
    "            lb = 0\n",
    "            ub = thre - n_col - lb\n",
    "            spectral_pad = np.pad(spectral,((0,0),(lb,ub)),\"constant\")\n",
    "        return(spectral_pad)\n",
    "        \n",
    "    def GenerateBatch(self,X,y,speaker_dict,time_len = 300,batch_size = 10,shuffle = True,margin_ms = 0):\n",
    "        num_classes = len(speaker_dict.keys())\n",
    "        while True:\n",
    "            if shuffle:\n",
    "                indexes = np.random.permutation(len(X))\n",
    "                X = X[indexes]\n",
    "                y = y[indexes]\n",
    "\n",
    "            for tmp_X,tmp_y in zip(X,y):\n",
    "                with open(tmp_X,\"rb\") as f:\n",
    "                    fr,t,spectral = pickle.load(f)\n",
    "                if (spectral.shape[1] - time_len) <= 0:\n",
    "                    lb_ms = 0\n",
    "                    ub_ms = spectral.shape[1]#\n",
    "                    #np.random.randint(margin_ms,spectral.shape[1])\n",
    "                else:\n",
    "                    lb_ms = np.random.randint(margin_ms,spectral.shape[1] - time_len)\n",
    "                    ub_ms = lb_ms + time_len\n",
    "\n",
    "                #周波数方向に正規化\n",
    "                spectral_norm = NormalizeHorizontalDirection(spectral[:,lb_ms:ub_ms])\n",
    "                # thre 以下の場合はpadding\n",
    "                spectral_norm = self.zero_padding(spectral_norm,time_len)\n",
    "                target = to_categorical(speaker_dict[tmp_y],num_classes=num_classes)\n",
    "                \n",
    "                self.spectrograms.append(spectral_norm)\n",
    "                self.labels.append(target)\n",
    "\n",
    "                if len(self.labels) == batch_size:\n",
    "                    inputs = np.asarray(self.spectrograms, dtype=np.float32).reshape(batch_size,\n",
    "                                                                                   spectral_norm.shape[0],\n",
    "                                                                                    spectral_norm.shape[1],1)\n",
    "                    targets = np.asarray(self.labels, dtype=np.float32)\n",
    "                    self.reset()\n",
    "                    yield (inputs,targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in train_datagen.GenerateBatch(X_train,y_train,label2int,batch_size = BATCH_SIZE):\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ジェネレータを生成\n",
    "train_datagen = SpectrogramDataGenerator()\n",
    "val_datagen = SpectrogramDataGenerator()\n",
    "\n",
    "# エポック数を設定\n",
    "NUM_EPOCHS = 2000\n",
    "\n",
    "# バッチサイズの設定\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# 1epoch当たりの学習につかうデータの量を設定\n",
    "# たとえば、N_MULTIが2の時、1epoch当たり学習データを2倍に増やし、学習。\n",
    "N_MULTI = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      " 446/3403 [==>...........................] - ETA: 26:49 - loss: 5.7715 - f1: 0.3089 - acc: 0.4323"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-24d8d26b1009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                            \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN_MULTI\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                            \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                            \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                           )\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             class_weight=class_weight)\n\u001b[0;32m-> 1212\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_uses_dynamic_learning_phase\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         return (self.uses_learning_phase and\n\u001b[0;32m--> 558\u001b[0;31m                 not isinstance(K.learning_phase(), int))\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mlearning_phase\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mLearning\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscalar\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mPython\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_LEARNING_PHASES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         phase = tf.placeholder_with_default(False,\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5559\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5560\u001b[0m   \"\"\"\n\u001b[0;32m-> 5561\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5563\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhas_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5202\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5203\u001b[0m     \u001b[0;34m\"\"\"Override that returns a global default if the stack is empty.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5204\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DefaultGraphStack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5206\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GetGlobalDefaultGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FIXME patience15は多すぎるかもしれない。8くらいで良いかも\n",
    "patience = 0\n",
    "es = EarlyStopping(monitor = \"val_loss\",\n",
    "                   patience = patience)\n",
    "\n",
    "mc = ModelCheckpoint(\"03_work/models/resnet/resnet_model.h5\",\n",
    "                    monitor = \"val_loss\",\n",
    "                    save_best_only = True,\n",
    "                    verbose = 1)\n",
    "\n",
    "# FIXME : momentumなどを用いて、最適化時間を短縮する。\n",
    "hist = model.fit_generator(generator = train_datagen.GenerateBatch(X_train,y_train,label2int,batch_size = BATCH_SIZE),\n",
    "                           epochs = NUM_EPOCHS,\n",
    "                           steps_per_epoch = int(np.ceil(len(X_train) * N_MULTI/ BATCH_SIZE)),\n",
    "                           validation_data = val_datagen.GenerateBatch(X_val,y_val,label2int,batch_size = BATCH_SIZE),\n",
    "                           validation_steps = int(np.ceil(len(X_val) * N_MULTI/ BATCH_SIZE)),\n",
    "                           callbacks = [mc,es],\n",
    "                           verbose = 1\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2intを保存する\n",
    "with open(\"03_work/label2int.pickle\",\"wb\") as f:\n",
    "    pickle.dump(label2int,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-da36d7f91995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 学習ログの保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     np.savetxt(\"03_work/models/logs/{0}.txt\".format(key),\n\u001b[1;32m      4\u001b[0m                \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                delimiter=\",\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "# 学習ログの保存\n",
    "for key in hist.history.keys():\n",
    "    np.savetxt(\"03_work/models/resnet/logs/{0}.txt\".format(key),\n",
    "               hist.history[key],\n",
    "               delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "03_work/models/logs/loss.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9846d4b7c052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 訓練履歴の可視化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## 履歴の読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"03_work/models/logs/loss.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"03_work/models/logs/acc.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: 03_work/models/logs/loss.txt not found."
     ]
    }
   ],
   "source": [
    "# 訓練履歴の可視化\n",
    "## 履歴の読み込み\n",
    "savedir = \"03_work/models/resnet/\"\n",
    "train_loss = np.loadtxt(\"03_work/models/resnet/logs/loss.txt\")\n",
    "train_acc = np.loadtxt(\"03_work/models/resnet/logs/acc.txt\")\n",
    "\n",
    "val_loss = np.loadtxt(\"03_work/models/resnet/logs/val_loss.txt\")\n",
    "val_acc = np.loadtxt(\"03_work/models/resnet/logs/val_acc.txt\")\n",
    "\n",
    "## 訓練誤差の履歴をプロット\n",
    "plt.figure()\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(range(len(train_loss)),train_loss,label = \"train_loss\")\n",
    "plt.plot(range(len(val_loss)),val_loss,label = \"val_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6fae740212d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_acc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e2406db00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 正解率の履歴をプロット\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(range(len(train_acc)),train_acc,label = \"train_acc\")\n",
    "plt.plot(range(len(val_acc)),val_acc,label = \"val_acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validationデータに対するLossが最も小さかったベストモデルの読み込み\n",
    "model = load_model(\"03_work/models/cnn_model_01.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ジェネレータを生成\n",
    "test_datagen = SpectrogramDataGenerator()\n",
    "\n",
    "# バッチサイズの設定\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# 1epoch当たりの学習につかうデータの量を設定\n",
    "N_MULTI = 1\n",
    "\n",
    "evaluation = model.evaluate_generator(generator = test_datagen.GenerateBatch(X_test,y_test,label2int,batch_size = BATCH_SIZE),\n",
    "                                     steps = int(np.ceil(len(X_test) * N_MULTI/ BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:0.117\n",
      "test_accuracy:0.962\n"
     ]
    }
   ],
   "source": [
    "# TODO : macro F1も計算する\n",
    "# TODO : label2intを保存する\n",
    "# 予測正解率を出力\n",
    "print(\"test_loss:%.3f\" % evaluation[0])\n",
    "print(\"test_accuracy:%.3f\" % evaluation[1])\n",
    "#print(\"test_macrof1:%3f\" %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bda8321812ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                          shuffle = False),\n\u001b[0;32m----> 7\u001b[0;31m                                  steps=int(np.ceil(len(X_test) * N_MULTI/BATCH_SIZE)))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO : \n",
    "BATCH_SIZE = 1\n",
    "y_pred = model.predict_generator(generator = \n",
    "                              test_datagen.GenerateBatch(X_test,y_test,label2int,\n",
    "                                                         batch_size= BATCH_SIZE,\n",
    "                                                         shuffle = False),\n",
    "                                 steps=int(np.ceil(len(X_test) * N_MULTI/BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmaxで予測ラベルを作成\n",
    "y_pred_label_int = np.argmax(y_pred,axis = 1)\n",
    "y_test_label_int = [label2int[l] for l in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "macrof1 = f1_score(y_test_label_int, y_pred_label_int, average='macro')\n",
    "print(\"test_macro-f1:%.3f\" % macrof1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
