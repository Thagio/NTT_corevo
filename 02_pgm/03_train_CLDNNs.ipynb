{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signateのデータに対してCLDNNsを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display # 波形のプロットに必要\n",
    "import IPython.display as ipd #jupyter-notebook上で音声再生\n",
    "import glob\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.signal as ss\n",
    "import os\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout,Input,Flatten,Activation\n",
    "from keras.layers import Conv1D,Conv2D,MaxPooling1D,BatchNormalization,Reshape\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "# モデル可視化用\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100%!important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# jupyter-notebookのcellの幅を広げる\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container{width:100%!important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを固定\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作業ディレクトリの設定\n",
    "os.chdir(\"/home/taichi/DataAnalysis/05_NTT_corevo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv(\"01_input/ntt_corevo/class_train.tsv\",\n",
    "                        delimiter = \"\\t\",\n",
    "                        names = [\"filename\",\"label\"])\n",
    "\n",
    "train_info[\"raw_wave_path\"] = \"03_work/raw_waves/train/\" + train_info[\"filename\"] + \".pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03_work/raw_waves/train/0002f1cd968ca78ada9e1c7037224773.pickle'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info[\"raw_wave_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルが存在するか確認\n",
    "#!ls -lad 03_work/raw_waves/train/0002f1cd968ca78ada9e1c7037224773.pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2dictをよみこみ\n",
    "with open(\"03_work/label2int.pickle\",mode = \"rb\") as f:\n",
    "    label2int = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FE_AD': 0, 'FE_CH': 1, 'FE_EL': 2, 'MA_AD': 3, 'MA_CH': 4, 'MA_EL': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsizeで割り切れない場合を考慮しないといけない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepathとlabelを入力として受け取るRAW_WAVE_GENERATORを実装\n",
    "class RawWaveGenerator(keras.callbacks.Callback):\n",
    "    def __init__(self,minibatchsize,duration_sec,data_df):\n",
    "        self.duration_sec = duration_sec\n",
    "        self.minibatchsize = minibatchsize \n",
    "        self.cur_index = 0\n",
    "      #  self.wave_length = wave_length\n",
    "#        self.step = step\n",
    "        self.data_df = data_df\n",
    "        self.data_size = data_df.shape[0]\n",
    "        self.iteration = np.floor(self.data_size/minibatchsize)\n",
    "        self.sr = 22050\n",
    "    def shuffle_df(self):\n",
    "        # 学習データの学習順序をシャッフル\n",
    "        self.data_df = self.data_df.sample(frac=1).reset_index(drop=True) #.loc[self.cur_index:self.cur_index+self.minibatchsize-1,:]\n",
    "    \n",
    "    def get_batch(self,minibatchsize,duration_sec):\n",
    "        inputs = np.zeros([minibatchsize,duration_sec*self.sr,1])\n",
    "        outputs = np.zeros(minibatchsize)\n",
    "        \n",
    "        train_batch_df = self.data_df.loc[self.cur_index:self.cur_index+self.minibatchsize-1,:]\n",
    "#        print(self.cur_index)\n",
    "#        print(self.cur_index+minibatchsize-1)\n",
    "#       print(train_batch_df)\n",
    "        for i,(index,v) in enumerate(train_batch_df.iterrows()):\n",
    "            #    print(v)\n",
    "           # print(i)\n",
    "            label = v[\"label\"]\n",
    "            wave_path = v[\"raw_wave_path\"]\n",
    "    \n",
    "            with open(wave_path,mode=\"rb\") as f:\n",
    "                tmp = pickle.load(f)\n",
    "                sr = tmp[\"sampling_rate\"]\n",
    "                raw_wave = tmp[\"raw_wave\"]\n",
    "\n",
    "            # 基本的にサンプリングレートは22050のはず\n",
    "            assert sr == 22050\n",
    "\n",
    "            # 変数名aは小さなスコープしかないから許して\n",
    "            a = raw_wave[:duration_sec*sr]\n",
    "            # データがduration秒\n",
    "            a = np.pad(a, [0,duration_sec*sr-len(a)],'constant')\n",
    "            \n",
    "#            print(a.shape)\n",
    "#            print(inputs.shape)\n",
    "#            print(i)\n",
    "\n",
    "            inputs[i,:,0] = a\n",
    "            outputs[i] = label2int[label]\n",
    "            \n",
    "        self.cur_index = self.cur_index + minibatchsize\n",
    "        \n",
    "        return (inputs,outputs)\n",
    "                \n",
    "    def next_train(self):\n",
    "        self.cur_index = 0\n",
    "        self.shuffle_df()\n",
    "        \n",
    "        while True:    \n",
    "            if self.cur_index / self.minibatchsize > self.iteration:\n",
    "                self.cur_index = 0\n",
    "            yield self.get_batch(minibatchsize = self.minibatchsize,\n",
    "                                 duration_sec = self.duration_sec)\n",
    "\n",
    "#    def next_val(self):\n",
    "#        while True:           \n",
    "#            yield self.get_batch(minibatchsize = self.minibatchsize,\n",
    "#                                 duration_sec = self.duration_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = RawWaveGenerator(minibatchsize=32,duration_sec=5,data_df=train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max([np.nan,np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,v in enumerate(data_gen.next_train()):\n",
    "    # 音声データの振幅がinfやnanでないか確認\n",
    "#    print(np.min(v[0]))\n",
    "#    if i == 5:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen.cur_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflowのデバッガを設定。lossがnanやinfになるとき、役に立つ\n",
    "def set_debugger_session():\n",
    "    sess = K.get_session()\n",
    "    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "    sess.add_tensor_filter('has_inf_or_nan', tf_debug.has_inf_or_nan)\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記デバッガはjupyter-notebook上で実行すると、ターミナル上で実行される。意外と便利\n",
    "#set_debugger_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLDNNsモデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43915482/how-do-you-create-a-custom-activation-function-with-keras\n",
    "# 上記参考\n",
    "def log_relu(x):\n",
    "    return(K.log(K.relu(x)+0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動でreshapeする関数を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ラベルの数\n",
    "output_dim = len(label2int)\n",
    "\n",
    "#学習モデルの構築\n",
    "sr = 22050\n",
    "duration_sec = 1\n",
    "#words_per_epoch = 16000\n",
    "val_split = 0.2\n",
    "#val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "#conv_filters = 256\n",
    "conv_filters = 400\n",
    "#kernel_size = (3, 3)\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "\n",
    "window_size_sec = 35 * (10 ** -3)\n",
    "\n",
    "#rnn_size = \n",
    "#minibatchsize = 32\n",
    "\n",
    "input_shape = [duration_sec*sr,1]\n",
    "    \n",
    "# TODO : Conv1Dに変更    \n",
    "\n",
    "act = 'relu'\n",
    "\n",
    "input_data = Input(name='the_input', \n",
    "                   shape=input_shape, \n",
    "                   dtype='float32')\n",
    "\n",
    "inner = Conv1D(filters = conv_filters, \n",
    "               kernel_size = int(window_size_sec * sr),\n",
    "               padding='valid',\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               name='conv1')(input_data)\n",
    "\n",
    "inner = MaxPooling1D(pool_size= duration_sec*sr - int(window_size_sec * sr) + 1, name='max1')(inner)\n",
    "\n",
    "inner = Activation(log_relu,name=\"act1\")(inner)\n",
    "#inner = Activation(\"relu\",name=\"act1\")(inner)\n",
    "#inner = Activation(log_relu,name=\"relu\")(inner)\n",
    "\n",
    "inner = Reshape((conv_filters,1),name=\"reshape1\")(inner)\n",
    "\n",
    "inner = Conv1D(filters=256,\n",
    "               kernel_size= 8, padding='valid',\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               activation=\"relu\",\n",
    "               name='conv2')(inner)\n",
    "\n",
    "#inner = Activation(log_relu,name=\"act2\")(inner)\n",
    "\n",
    "inner = MaxPooling1D(pool_size=3, \n",
    "                     name='max2')(inner)\n",
    "\n",
    "timesteps = 32\n",
    "data_dim = 512\n",
    "rnn_size = 832\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm1\")(inner)\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm2\")(inner)\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm3\")(inner)\n",
    "\n",
    "inner = Flatten(name = \"flatten\")(inner)\n",
    "\n",
    "inner = Dense(1024,name = \"dense1\")(inner)\n",
    "\n",
    "inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "out = Dense(output_dim,activation=\"sigmoid\",name = \"dense2\")(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=out)\n",
    "\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=sgd,metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 22050, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 21280, 400)        308800    \n",
      "_________________________________________________________________\n",
      "max1 (MaxPooling1D)          (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "reshape1 (Reshape)           (None, 400, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 393, 256)          2304      \n",
      "_________________________________________________________________\n",
      "max2 (MaxPooling1D)          (None, 131, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 131, 832)          3624192   \n",
      "_________________________________________________________________\n",
      "lstm2 (LSTM)                 (None, 131, 832)          5541120   \n",
      "_________________________________________________________________\n",
      "lstm3 (LSTM)                 (None, 131, 832)          5541120   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 108992)            0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 1024)              111608832 \n",
      "_________________________________________________________________\n",
      "batch_norm1 (BatchNormalizat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 126,636,614\n",
      "Trainable params: 126,634,566\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info_shuffle = train_info.sample(frac=1.0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_info_shuffle.loc[0:int(train_info.shape[0]*train_rate),]\n",
    "val_df = train_info_shuffle.loc[int(train_info.shape[0]*train_rate) + 1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatchsize = 5\n",
    "train_gen = RawWaveGenerator(minibatchsize=minibatchsize,duration_sec=duration_sec,data_df=train_df)\n",
    "val_gen = RawWaveGenerator(minibatchsize=minibatchsize,duration_sec=duration_sec,data_df=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[108992,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/SGD/Square_13}} = Square[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/SGD/gradients/dense1_3/MatMul_grad/MatMul_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-48f9aba17692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                initial_epoch=start_epoch)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[108992,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/SGD/Square_13}} = Square[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/SGD/gradients/dense1_3/MatMul_grad/MatMul_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 100\n",
    "hist = model.fit_generator(generator=train_gen.next_train(),\n",
    "                               steps_per_epoch=1000,\n",
    "                               epochs=100,\n",
    "                               validation_data=val_gen.next_train(),\n",
    "                               validation_steps=50,\n",
    "                               initial_epoch=start_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
