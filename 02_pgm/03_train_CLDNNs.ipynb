{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signateのデータに対してCLDNNsを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display # 波形のプロットに必要\n",
    "import IPython.display as ipd #jupyter-notebook上で音声再生\n",
    "import glob\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.signal as ss\n",
    "import os\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout,Input,Flatten,Activation\n",
    "from keras.layers import Conv1D,Conv2D,MaxPooling1D,BatchNormalization,Reshape\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "# モデル可視化用\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100%!important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# jupyter-notebookのcellの幅を広げる\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container{width:100%!important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを固定\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作業ディレクトリの設定\n",
    "os.chdir(\"/home/taichi/DataAnalysis/05_NTT_corevo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv(\"01_input/ntt_corevo/class_train.tsv\",\n",
    "                        delimiter = \"\\t\",\n",
    "                        names = [\"filename\",\"label\"])\n",
    "\n",
    "train_info[\"raw_wave_path\"] = \"03_work/raw_waves/train/\" + train_info[\"filename\"] + \".pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03_work/raw_waves/train/0002f1cd968ca78ada9e1c7037224773.pickle'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info[\"raw_wave_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルが存在するか確認\n",
    "#!ls -lad 03_work/raw_waves/train/0002f1cd968ca78ada9e1c7037224773.pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2dictをよみこみ\n",
    "with open(\"03_work/label2int.pickle\",mode = \"rb\") as f:\n",
    "    label2int = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FE_AD': 0, 'FE_CH': 1, 'FE_EL': 2, 'MA_AD': 3, 'MA_CH': 4, 'MA_EL': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsizeで割り切れない場合を考慮しないといけない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepathとlabelを入力として受け取るRAW_WAVE_GENERATORを実装\n",
    "class RawWaveGenerator(keras.callbacks.Callback):\n",
    "    def __init__(self,minibatchsize,duration_sec,data_df):\n",
    "        self.duration_sec = duration_sec\n",
    "        self.minibatchsize = minibatchsize \n",
    "        self.cur_index = 0\n",
    "      #  self.wave_length = wave_length\n",
    "#        self.step = step\n",
    "        self.data_df = data_df\n",
    "        self.data_size = data_df.shape[0]\n",
    "        self.iteration = np.floor(self.data_size/minibatchsize)\n",
    "        self.sr = 22050\n",
    "    def shuffle_df(self):\n",
    "        # 学習データの学習順序をシャッフル\n",
    "        self.data_df = self.data_df.sample(frac=1).reset_index(drop=True) #.loc[self.cur_index:self.cur_index+self.minibatchsize-1,:]\n",
    "    \n",
    "    def get_batch(self,minibatchsize,duration_sec):\n",
    "        inputs = np.zeros([minibatchsize,duration_sec*self.sr,1])\n",
    "        outputs = np.zeros(minibatchsize)\n",
    "        \n",
    "        train_batch_df = self.data_df.loc[self.cur_index:self.cur_index+self.minibatchsize-1,:]\n",
    "#        print(self.cur_index)\n",
    "#        print(self.cur_index+minibatchsize-1)\n",
    "#       print(train_batch_df)\n",
    "        for i,(index,v) in enumerate(train_batch_df.iterrows()):\n",
    "            #    print(v)\n",
    "           # print(i)\n",
    "            label = v[\"label\"]\n",
    "            wave_path = v[\"raw_wave_path\"]\n",
    "    \n",
    "            with open(wave_path,mode=\"rb\") as f:\n",
    "                tmp = pickle.load(f)\n",
    "                sr = tmp[\"sampling_rate\"]\n",
    "                raw_wave = tmp[\"raw_wave\"]\n",
    "\n",
    "            # 基本的にサンプリングレートは22050のはず\n",
    "            assert sr == 22050\n",
    "\n",
    "            # 変数名aは小さなスコープしかないから許して\n",
    "            a = raw_wave[:duration_sec*sr]\n",
    "            # データがduration秒\n",
    "            a = np.pad(a, [0,duration_sec*sr-len(a)],'constant')\n",
    "            \n",
    "#            print(a.shape)\n",
    "#            print(inputs.shape)\n",
    "#            print(i)\n",
    "\n",
    "            inputs[i,:,0] = a\n",
    "            outputs[i] = label2int[label]\n",
    "            \n",
    "        self.cur_index = self.cur_index + minibatchsize\n",
    "        \n",
    "        return (inputs,outputs)\n",
    "                \n",
    "    def next_train(self):\n",
    "        self.cur_index = 0\n",
    "        self.shuffle_df()\n",
    "        \n",
    "        while True:    \n",
    "            if self.cur_index / self.minibatchsize > self.iteration:\n",
    "                self.cur_index = 0\n",
    "            yield self.get_batch(minibatchsize = self.minibatchsize,\n",
    "                                 duration_sec = self.duration_sec)\n",
    "\n",
    "#    def next_val(self):\n",
    "#        while True:           \n",
    "#            yield self.get_batch(minibatchsize = self.minibatchsize,\n",
    "#                                 duration_sec = self.duration_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_gen = RawWaveGenerator(minibatchsize=32,duration_sec=5,data_df=train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max([np.nan,np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,v in enumerate(data_gen.next_train()):\n",
    "    # 音声データの振幅がinfやnanでないか確認\n",
    "#    print(np.min(v[0]))\n",
    "#    if i == 5:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_gen.cur_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflowのデバッガを設定。lossがnanやinfになるとき、役に立つ\n",
    "def set_debugger_session():\n",
    "    sess = K.get_session()\n",
    "    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "    sess.add_tensor_filter('has_inf_or_nan', tf_debug.has_inf_or_nan)\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記デバッガはjupyter-notebook上で実行すると、ターミナル上で実行される。意外と便利\n",
    "#set_debugger_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLDNNsモデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43915482/how-do-you-create-a-custom-activation-function-with-keras\n",
    "# 上記参考\n",
    "def log_relu(x):\n",
    "    return(K.log(K.relu(x)+0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動でreshapeする関数を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamのデフォルト学習率に設定\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ラベルの数\n",
    "output_dim = len(label2int)\n",
    "\n",
    "#学習モデルの構築\n",
    "sr = 22050\n",
    "duration_sec = 3\n",
    "#words_per_epoch = 16000\n",
    "#val_split = 0.2\n",
    "#val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "#conv_filters = 256\n",
    "conv_filters = 400\n",
    "#kernel_size = (3, 3)\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "\n",
    "window_size_sec = 35 * (10 ** -3)\n",
    "\n",
    "#rnn_size = \n",
    "#minibatchsize = 32\n",
    "\n",
    "input_shape = [duration_sec*sr,1]\n",
    "    \n",
    "# TODO : Conv1Dに変更    \n",
    "\n",
    "act = 'relu'\n",
    "\n",
    "input_data = Input(name='the_input', \n",
    "                   shape=input_shape, \n",
    "                   dtype='float32')\n",
    "\n",
    "inner = Conv1D(filters = conv_filters, \n",
    "               kernel_size = int(window_size_sec * sr),\n",
    "               padding='valid',\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               name='conv1')(input_data)\n",
    "\n",
    "inner = MaxPooling1D(pool_size= duration_sec*sr - int(window_size_sec * sr) + 1, name='max1')(inner)\n",
    "\n",
    "inner = Activation(log_relu,name=\"act1\")(inner)\n",
    "#inner = Activation(\"relu\",name=\"act1\")(inner)\n",
    "#inner = Activation(log_relu,name=\"relu\")(inner)\n",
    "\n",
    "inner = Reshape((conv_filters,1),name=\"reshape1\")(inner)\n",
    "\n",
    "inner = Conv1D(filters=256,\n",
    "               kernel_size= 8, padding='valid',\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               activation=\"relu\",#linear\n",
    "               name='conv2')(inner)\n",
    "\n",
    "#inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "# 以下のactivationをするなら、conv2のactをlinearにする\n",
    "#inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "\n",
    "inner = MaxPooling1D(pool_size = 3, \n",
    "                     name='max2')(inner)\n",
    "\n",
    "timesteps = 32\n",
    "data_dim = 512\n",
    "rnn_size = 832\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm1\")(inner)\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm2\")(inner)\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm3\")(inner)\n",
    "\n",
    "inner = Flatten(name = \"flatten\")(inner)\n",
    "\n",
    "inner = Dense(1024,name = \"dense1\")(inner)\n",
    "\n",
    "inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "out = Dense(output_dim,activation=\"sigmoid\",name = \"dense2\")(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=out)\n",
    "\n",
    "#lr = 0.001でうまくいかなければ、ADAMにしてもよいかも\n",
    "# callbacksにf1 scoreを追加したい\n",
    "# https://qiita.com/koshian2/items/81abfc0a75ea99f726b9\n",
    "\n",
    "sgd = SGD(lr=LEARNING_RATE,\n",
    "          decay=1e-6, \n",
    "          momentum=0.9,\n",
    "          nesterov=True,\n",
    "          clipnorm=5)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=sgd,metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 66150, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 65380, 400)        308800    \n",
      "_________________________________________________________________\n",
      "max1 (MaxPooling1D)          (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "reshape1 (Reshape)           (None, 400, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 393, 256)          2304      \n",
      "_________________________________________________________________\n",
      "max2 (MaxPooling1D)          (None, 131, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 131, 832)          3624192   \n",
      "_________________________________________________________________\n",
      "lstm2 (LSTM)                 (None, 131, 832)          5541120   \n",
      "_________________________________________________________________\n",
      "lstm3 (LSTM)                 (None, 131, 832)          5541120   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 108992)            0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 1024)              111608832 \n",
      "_________________________________________________________________\n",
      "batch_norm1 (BatchNormalizat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 126,636,614\n",
      "Trainable params: 126,634,566\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info_shuffle = train_info.sample(frac=1.0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_info_shuffle.loc[0:int(train_info.shape[0]*train_rate),]\n",
    "val_df = train_info_shuffle.loc[int(train_info.shape[0]*train_rate) + 1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 5\n",
    "\n",
    "train_gen = RawWaveGenerator(minibatchsize=BATCHSIZE,duration_sec=duration_sec,data_df=train_df)\n",
    "val_gen = RawWaveGenerator(minibatchsize=BATCHSIZE,duration_sec=duration_sec,data_df=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 5\n",
    "es = EarlyStopping(monitor = \"val_loss\",\n",
    "                   patience = patience)\n",
    "\n",
    "mc = ModelCheckpoint(\"03_work/models/cldnns/cldnns_model.h5\",\n",
    "                    monitor = \"val_loss\",\n",
    "                    save_best_only = True,\n",
    "                    verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train_df.shape[0]\n",
    "val_size = val_df.shape[0]\n",
    "steps_per_epoch = np.ceil(train_size / BATCHSIZE)\n",
    "steps_per_epoch_val = np.ceil(val_size / BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#デバッグ用\n",
    "#steps_per_epoch = 10\n",
    "#steps_per_epoch_val = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  45/6049 [..............................] - ETA: 1:41:29 - loss: 1.8153 - acc: 0.2178"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "EPOCHS = 100\n",
    "#STEP_PER_EPOCH = \n",
    "\n",
    "hist = model.fit_generator(generator=train_gen.next_train(),\n",
    "                               steps_per_epoch=steps_per_epoch,\n",
    "                               epochs=EPOCHS,\n",
    "                               validation_data=val_gen.next_train(),\n",
    "                               validation_steps=steps_per_epoch_val,\n",
    "                               initial_epoch=start_epoch,\n",
    "                          callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ログの保存\n",
    "for key in hist.history.keys():\n",
    "    np.savetxt(\"03_work/models/cldnns/logs/{0}.txt\".format(key),\n",
    "               hist.history[key],\n",
    "               delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
