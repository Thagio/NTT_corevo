{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signateのデータに対してCLDNNsを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display # 波形のプロットに必要\n",
    "import IPython.display as ipd #jupyter-notebook上で音声再生\n",
    "import glob\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.signal as ss\n",
    "import os\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout,Input,Flatten,Activation\n",
    "from keras.layers import Conv1D,Conv2D,MaxPooling1D,BatchNormalization,Reshape\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "# モデル可視化用\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100%!important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# jupyter-notebookのcellの幅を広げる\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container{width:100%!important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを固定\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作業ディレクトリの設定\n",
    "os.chdir(\"/home/taichi/DataAnalysis/05_NTT_corevo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv(\"01_input/ntt_corevo/class_train.tsv\",\n",
    "                        delimiter = \"\\t\",\n",
    "                        names = [\"filename\",\"label\"])\n",
    "\n",
    "train_info[\"raw_wave_path\"] = \"03_work/raw_waves/train/\" + train_info[\"filename\"] + \".pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03_work/raw_waves/train/0002f1cd968ca78ada9e1c7037224773.pickle'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info[\"raw_wave_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルが存在するか確認\n",
    "#!ls -lad 03_work/raw_waves/train/0002f1cd968ca78ada9e1c7037224773.pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2dictをよみこみ\n",
    "with open(\"03_work/label2int.pickle\",mode = \"rb\") as f:\n",
    "    label2int = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FE_AD': 0, 'FE_CH': 1, 'FE_EL': 2, 'MA_AD': 3, 'MA_CH': 4, 'MA_EL': 5}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_wave_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002f1cd968ca78ada9e1c7037224773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0002f1cd968ca78ada9e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003747ec9268461d4cbb9e1b86e9663</td>\n",
       "      <td>FE_AD</td>\n",
       "      <td>03_work/raw_waves/train/0003747ec9268461d4cbb9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003b32f378b001f0f73bf0981da8773</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0003b32f378b001f0f73bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ab975bf8b59e1b19f2b7b6d1548b</td>\n",
       "      <td>MA_CH</td>\n",
       "      <td>03_work/raw_waves/train/0004ab975bf8b59e1b19f2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005678b57ca265a65f8ef0cc7481277</td>\n",
       "      <td>MA_AD</td>\n",
       "      <td>03_work/raw_waves/train/0005678b57ca265a65f8ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label  \\\n",
       "0  0002f1cd968ca78ada9e1c7037224773  MA_CH   \n",
       "1  0003747ec9268461d4cbb9e1b86e9663  FE_AD   \n",
       "2  0003b32f378b001f0f73bf0981da8773  MA_CH   \n",
       "3  0004ab975bf8b59e1b19f2b7b6d1548b  MA_CH   \n",
       "4  0005678b57ca265a65f8ef0cc7481277  MA_AD   \n",
       "\n",
       "                                       raw_wave_path  \n",
       "0  03_work/raw_waves/train/0002f1cd968ca78ada9e1c...  \n",
       "1  03_work/raw_waves/train/0003747ec9268461d4cbb9...  \n",
       "2  03_work/raw_waves/train/0003b32f378b001f0f73bf...  \n",
       "3  03_work/raw_waves/train/0004ab975bf8b59e1b19f2...  \n",
       "4  03_work/raw_waves/train/0005678b57ca265a65f8ef...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsizeで割り切れない場合を考慮しないといけない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepathとlabelを入力として受け取るRAW_WAVE_GENERATORを実装\n",
    "class RawWaveGenerator(keras.callbacks.Callback):\n",
    "    def __init__(self,minibatchsize,duration_sec,data_df,shuffle = True):\n",
    "        self.duration_sec = duration_sec\n",
    "        self.minibatchsize = minibatchsize \n",
    "        self.cur_index = 0\n",
    "      #  self.wave_length = wave_length\n",
    "#        self.step = step\n",
    "        self.data_df = data_df\n",
    "        self.data_size = data_df.shape[0]\n",
    "        self.iteration = np.floor(self.data_size/minibatchsize)\n",
    "        self.sr = 22050\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def shuffle_df(self):\n",
    "        # 学習データの学習順序をシャッフル\n",
    "        self.data_df = self.data_df.sample(frac=1).reset_index(drop=True) #.loc[self.cur_index:self.cur_index+self.minibatchsize-1,:]\n",
    "    \n",
    "    def get_batch(self,minibatchsize,duration_sec):\n",
    "        inputs = np.zeros([minibatchsize,duration_sec*self.sr,1])\n",
    "        outputs = np.zeros(minibatchsize)\n",
    "        \n",
    "        train_batch_df = self.data_df.loc[self.cur_index:self.cur_index+self.minibatchsize-1,:]\n",
    "#        print(self.cur_index)\n",
    "#        print(self.cur_index+minibatchsize-1)\n",
    "#       print(train_batch_df)\n",
    "        for i,(index,v) in enumerate(train_batch_df.iterrows()):\n",
    "            #    print(v)\n",
    "           # print(i)\n",
    "            label = v[\"label\"]\n",
    "            wave_path = v[\"raw_wave_path\"]\n",
    "    \n",
    "            with open(wave_path,mode=\"rb\") as f:\n",
    "                tmp = pickle.load(f)\n",
    "                sr = tmp[\"sampling_rate\"]\n",
    "                raw_wave = tmp[\"raw_wave\"]\n",
    "\n",
    "            # 基本的にサンプリングレートは22050のはず\n",
    "            assert sr == 22050\n",
    "\n",
    "            # 変数名aは小さなスコープしかないから許して\n",
    "            a = raw_wave[:duration_sec*sr]\n",
    "            # データがduration秒\n",
    "            a = np.pad(a, [0,duration_sec*sr-len(a)],'constant')\n",
    "            \n",
    "#            print(a.shape)\n",
    "#            print(inputs.shape)\n",
    "#            print(i)\n",
    "\n",
    "            inputs[i,:,0] = a\n",
    "            outputs[i] = label2int[label]\n",
    "            \n",
    "        self.cur_index = self.cur_index + minibatchsize\n",
    "        \n",
    "        return (inputs,outputs)\n",
    "                \n",
    "    def next_train(self):\n",
    "        self.cur_index = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.shuffle_df()\n",
    "        \n",
    "        while True:    \n",
    "            if self.cur_index / self.minibatchsize > self.iteration:\n",
    "                self.cur_index = 0\n",
    "            yield self.get_batch(minibatchsize = self.minibatchsize,\n",
    "                                 duration_sec = self.duration_sec)\n",
    "\n",
    "#    def next_val(self):\n",
    "#        while True:           \n",
    "#            yield self.get_batch(minibatchsize = self.minibatchsize,\n",
    "#                                 duration_sec = self.duration_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_gen = RawWaveGenerator(minibatchsize=32,duration_sec=5,data_df=train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max([np.nan,np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,v in enumerate(data_gen.next_train()):\n",
    "    # 音声データの振幅がinfやnanでないか確認\n",
    "#    print(np.min(v[0]))\n",
    "#    if i == 5:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_gen.cur_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflowのデバッガを設定。lossがnanやinfになるとき、役に立つ\n",
    "def set_debugger_session():\n",
    "    sess = K.get_session()\n",
    "    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "    sess.add_tensor_filter('has_inf_or_nan', tf_debug.has_inf_or_nan)\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記デバッガはjupyter-notebook上で実行すると、ターミナル上で実行される。意外と便利\n",
    "#set_debugger_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLDNNsモデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43915482/how-do-you-create-a-custom-activation-function-with-keras\n",
    "# 上記参考\n",
    "def log_relu(x):\n",
    "    return(K.log(K.relu(x)+0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動でreshapeする関数を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamのデフォルト学習率に設定\n",
    "# LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1loss, macro_f1 metricsを定義\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    \n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#学習モデルの構築\\nsr = 22050\\nduration_sec = 3\\n#words_per_epoch = 16000\\n#val_split = 0.2\\n#val_words = int(words_per_epoch * (val_split))\\n\\n#conv_filters = 256\\nconv_filters = 400\\n#kernel_size = (3, 3)\\nkernel_size = 3\\npool_size = 2\\ntime_dense_size = 32\\n\\nwindow_size_sec = 35 * (10 ** -3)\\n\\n#rnn_size = \\n#minibatchsize = 32\\n\\ninput_shape = [duration_sec*sr,1]\\n    \\n# TODO : Conv1Dに変更    \\n\\nact = \\'relu\\'\\n\\ninput_data = Input(name=\\'the_input\\', \\n                   shape=input_shape, \\n                   dtype=\\'float32\\')\\n\\ninner = Conv1D(filters = conv_filters, \\n               kernel_size = int(window_size_sec * sr),\\n               padding=\\'valid\\',\\n               kernel_initializer=\\'glorot_uniform\\',\\n               name=\\'conv1\\')(input_data)\\n\\ninner = MaxPooling1D(pool_size= duration_sec*sr - int(window_size_sec * sr) + 1, name=\\'max1\\')(inner)\\n\\ninner = Activation(log_relu,name=\"act1\")(inner)\\n#inner = Activation(\"relu\",name=\"act1\")(inner)\\n#inner = Activation(log_relu,name=\"relu\")(inner)\\n\\ninner = Reshape((conv_filters,1),name=\"reshape1\")(inner)\\n\\ninner = Conv1D(filters=256,\\n               kernel_size= 8, padding=\\'valid\\',\\n               kernel_initializer=\\'glorot_uniform\\',\\n               activation=\"relu\",#linear\\n               name=\\'conv2\\')(inner)\\n\\n#inner = BatchNormalization(name=\"batch_norm1\")(inner)\\n\\n# 以下のactivationをするなら、conv2のactをlinearにする\\n#inner = Activation(\"relu\",name=\"act2\")(inner)\\n\\n\\ninner = MaxPooling1D(pool_size = 3, \\n                     name=\\'max2\\')(inner)\\n\\ntimesteps = 32\\ndata_dim = 512\\nrnn_size = 832\\n\\ninner = LSTM(rnn_size, return_sequences=True,\\n             input_shape=(timesteps, data_dim),\\n            name = \"lstm1\")(inner)\\n\\ninner = LSTM(rnn_size, return_sequences=True,\\n             input_shape=(timesteps, data_dim),\\n            name = \"lstm2\")(inner)\\n\\ninner = LSTM(rnn_size, return_sequences=True,\\n             input_shape=(timesteps, data_dim),\\n            name = \"lstm3\")(inner)\\n\\ninner = Flatten(name = \"flatten\")(inner)\\n\\ninner = Dense(1024,name = \"dense1\")(inner)\\n\\ninner = BatchNormalization(name=\"batch_norm1\")(inner)\\n\\ninner = Activation(\"relu\",name=\"act2\")(inner)\\n\\nout = Dense(output_dim,activation=\"sigmoid\",name = \"dense2\")(inner)\\n\\nmodel = Model(inputs=input_data, outputs=out)\\n\\n#lr = 0.001でうまくいかなければ、ADAMにしてもよいかも\\n# callbacksにf1 scoreを追加したい\\n# https://qiita.com/koshian2/items/81abfc0a75ea99f726b9\\n\\nsgd = SGD(lr=LEARNING_RATE,\\n          decay=1e-6, \\n          momentum=0.9,\\n          nesterov=True,\\n          clipnorm=5)\\n\\nmodel.compile(loss = \"sparse_categorical_crossentropy\", optimizer=sgd,metrics = [\"accuracy\"])\\n\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ラベルの数\n",
    "output_dim = len(label2int)\n",
    "\n",
    "\"\"\"\n",
    "#学習モデルの構築\n",
    "sr = 22050\n",
    "duration_sec = 3\n",
    "#words_per_epoch = 16000\n",
    "#val_split = 0.2\n",
    "#val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "#conv_filters = 256\n",
    "conv_filters = 400\n",
    "#kernel_size = (3, 3)\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "\n",
    "window_size_sec = 35 * (10 ** -3)\n",
    "\n",
    "#rnn_size = \n",
    "#minibatchsize = 32\n",
    "\n",
    "input_shape = [duration_sec*sr,1]\n",
    "    \n",
    "# TODO : Conv1Dに変更    \n",
    "\n",
    "act = 'relu'\n",
    "\n",
    "input_data = Input(name='the_input', \n",
    "                   shape=input_shape, \n",
    "                   dtype='float32')\n",
    "\n",
    "inner = Conv1D(filters = conv_filters, \n",
    "               kernel_size = int(window_size_sec * sr),\n",
    "               padding='valid',\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               name='conv1')(input_data)\n",
    "\n",
    "inner = MaxPooling1D(pool_size= duration_sec*sr - int(window_size_sec * sr) + 1, name='max1')(inner)\n",
    "\n",
    "inner = Activation(log_relu,name=\"act1\")(inner)\n",
    "#inner = Activation(\"relu\",name=\"act1\")(inner)\n",
    "#inner = Activation(log_relu,name=\"relu\")(inner)\n",
    "\n",
    "inner = Reshape((conv_filters,1),name=\"reshape1\")(inner)\n",
    "\n",
    "inner = Conv1D(filters=256,\n",
    "               kernel_size= 8, padding='valid',\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               activation=\"relu\",#linear\n",
    "               name='conv2')(inner)\n",
    "\n",
    "#inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "# 以下のactivationをするなら、conv2のactをlinearにする\n",
    "#inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "\n",
    "inner = MaxPooling1D(pool_size = 3, \n",
    "                     name='max2')(inner)\n",
    "\n",
    "timesteps = 32\n",
    "data_dim = 512\n",
    "rnn_size = 832\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm1\")(inner)\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm2\")(inner)\n",
    "\n",
    "inner = LSTM(rnn_size, return_sequences=True,\n",
    "             input_shape=(timesteps, data_dim),\n",
    "            name = \"lstm3\")(inner)\n",
    "\n",
    "inner = Flatten(name = \"flatten\")(inner)\n",
    "\n",
    "inner = Dense(1024,name = \"dense1\")(inner)\n",
    "\n",
    "inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "out = Dense(output_dim,activation=\"sigmoid\",name = \"dense2\")(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=out)\n",
    "\n",
    "#lr = 0.001でうまくいかなければ、ADAMにしてもよいかも\n",
    "# callbacksにf1 scoreを追加したい\n",
    "# https://qiita.com/koshian2/items/81abfc0a75ea99f726b9\n",
    "\n",
    "sgd = SGD(lr=LEARNING_RATE,\n",
    "          decay=1e-6, \n",
    "          momentum=0.9,\n",
    "          nesterov=True,\n",
    "          clipnorm=5)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=sgd,metrics = [\"accuracy\"])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モデル、コールバックの定義\n",
    "def build_cldnns(input_shape,num_classes):    \n",
    "    # ラベルの数\n",
    "    output_dim = num_classes\n",
    "\n",
    "    #学習モデルの構築\n",
    "#    sr = 22050\n",
    " #   duration_sec = 3\n",
    "\n",
    "    conv_filters = 400\n",
    "    \n",
    "    kernel_size = 3\n",
    "#    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "\n",
    "    window_size_sec = 35 * (10 ** -3)\n",
    "\n",
    "#    input_shape = [duration_sec*sr,1]\n",
    "\n",
    "    # TODO : Conv1Dに変更    \n",
    "\n",
    "    act = 'relu'\n",
    "\n",
    "    input_data = Input(name='the_input', \n",
    "                       shape=input_shape, \n",
    "                       dtype='float32')\n",
    "\n",
    "    inner = Conv1D(filters = conv_filters, \n",
    "                   kernel_size = int(window_size_sec * sr),\n",
    "                   padding='valid',\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   name='conv1')(input_data)\n",
    "\n",
    "    inner = MaxPooling1D(pool_size= duration_sec*sr - int(window_size_sec * sr) + 1, name='max1')(inner)\n",
    "\n",
    "    inner = Activation(log_relu,name=\"act1\")(inner)\n",
    "    #inner = Activation(\"relu\",name=\"act1\")(inner)\n",
    "    #inner = Activation(log_relu,name=\"relu\")(inner)\n",
    "\n",
    "    inner = Reshape((conv_filters,1),name=\"reshape1\")(inner)\n",
    "\n",
    "    inner = Conv1D(filters=256,\n",
    "                   kernel_size= 8, padding='valid',\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   activation=\"relu\",#linear\n",
    "                   name='conv2')(inner)\n",
    "\n",
    "    #inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "    # 以下のactivationをするなら、conv2のactをlinearにする\n",
    "    #inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "\n",
    "    inner = MaxPooling1D(pool_size = 3, \n",
    "                         name='max2')(inner)\n",
    "\n",
    "    timesteps = 32\n",
    "    data_dim = 512\n",
    "    rnn_size = 832\n",
    "\n",
    "    inner = LSTM(rnn_size, return_sequences=True,\n",
    "                 input_shape=(timesteps, data_dim),\n",
    "                 name = \"lstm1\")(inner)\n",
    "\n",
    "    inner = LSTM(rnn_size, return_sequences=True,\n",
    "                 input_shape=(timesteps, data_dim),\n",
    "                 name = \"lstm2\")(inner)\n",
    "\n",
    "    inner = LSTM(rnn_size, return_sequences=True,\n",
    "                 input_shape=(timesteps, data_dim),\n",
    "                 name = \"lstm3\")(inner)\n",
    "\n",
    "    inner = Flatten(name = \"flatten\")(inner)\n",
    "\n",
    "    inner = Dense(1024,name = \"dense1\")(inner)\n",
    "\n",
    "    inner = BatchNormalization(name=\"batch_norm1\")(inner)\n",
    "\n",
    "    inner = Activation(\"relu\",name=\"act2\")(inner)\n",
    "\n",
    "    out = Dense(output_dim,activation=\"sigmoid\",name = \"dense2\")(inner)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=out)\n",
    "\n",
    "    #lr = 0.001でうまくいかなければ、ADAMにしてもよいかも\n",
    "    # callbacksにf1 scoreを追加したい\n",
    "    # https://qiita.com/koshian2/items/81abfc0a75ea99f726b9\n",
    "    \n",
    "    # Adamのデフォルト学習率に設定\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "    sgd = SGD(lr=LEARNING_RATE,\n",
    "              decay=1e-6, \n",
    "              momentum=0.9,\n",
    "              nesterov=True,\n",
    "              clipnorm=5)\n",
    "\n",
    "    model.compile(loss = f1_loss,\n",
    "                  optimizer=sgd,\n",
    "                  metrics = [f1,\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_sec = 3\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape =  [duration_sec*sr,1]\n",
    "num_classes = len(label2int)\n",
    "                \n",
    "model = build_cldnns(input_shape,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 66150, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 65380, 400)        308800    \n",
      "_________________________________________________________________\n",
      "max1 (MaxPooling1D)          (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "reshape1 (Reshape)           (None, 400, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 393, 256)          2304      \n",
      "_________________________________________________________________\n",
      "max2 (MaxPooling1D)          (None, 131, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 131, 832)          3624192   \n",
      "_________________________________________________________________\n",
      "lstm2 (LSTM)                 (None, 131, 832)          5541120   \n",
      "_________________________________________________________________\n",
      "lstm3 (LSTM)                 (None, 131, 832)          5541120   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 108992)            0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 1024)              111608832 \n",
      "_________________________________________________________________\n",
      "batch_norm1 (BatchNormalizat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 126,636,614\n",
      "Trainable params: 126,634,566\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info_shuffle = train_info.sample(frac=1.0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_info_shuffle.loc[0:int(train_info.shape[0]*train_rate),]\n",
    "val_df = train_info_shuffle.loc[int(train_info.shape[0]*train_rate) + 1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 5\n",
    "\n",
    "train_gen = RawWaveGenerator(minibatchsize=BATCHSIZE,duration_sec=duration_sec,data_df=train_df)\n",
    "val_gen = RawWaveGenerator(minibatchsize=BATCHSIZE,duration_sec=duration_sec,data_df=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 5\n",
    "es = EarlyStopping(monitor = \"val_loss\",\n",
    "                   patience = patience)\n",
    "\n",
    "mc = ModelCheckpoint(\"03_work/models/cldnns/cldnns_model.h5\",\n",
    "                    monitor = \"val_loss\",\n",
    "                    save_best_only = True,\n",
    "                    verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train_df.shape[0]\n",
    "val_size = val_df.shape[0]\n",
    "steps_per_epoch = np.ceil(train_size / BATCHSIZE)\n",
    "steps_per_epoch_val = np.ceil(val_size / BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#デバッグ用\n",
    "#steps_per_epoch = 10\n",
    "#steps_per_epoch_val = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 816/6049 [===>..........................] - ETA: 1:20:15 - loss: -0.2800 - f1: 1.3613 - acc: 0.0699"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-4b3a2f70ddd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                           callbacks=[es,mc])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newest/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "EPOCHS = 100\n",
    "#STEP_PER_EPOCH = \n",
    "\n",
    "hist = model.fit_generator(generator=train_gen.next_train(),\n",
    "                               steps_per_epoch=steps_per_epoch,\n",
    "                               epochs=EPOCHS,\n",
    "                               validation_data=val_gen.next_train(),\n",
    "                               validation_steps=steps_per_epoch_val,\n",
    "                               initial_epoch=start_epoch,\n",
    "                          callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ログの保存\n",
    "for key in hist.history.keys():\n",
    "    np.savetxt(\"03_work/models/cldnns/logs/{0}.txt\".format(key),\n",
    "               hist.history[key],\n",
    "               delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
